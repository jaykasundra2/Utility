### Most Common
- **Pandas**
- **NumPy**
- **SciPy**
- **Statsmodels**

### EDA
- **Pandas-profiling**: For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:
    - Type inference: detect the types of columns in a dataframe.
    - Essentials: type, unique values, missing values
    - Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range
    - Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness
    - Most frequent values
    - Histogram
    - Correlations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices
    - Missing values matrix, count, heatmap and dendrogram of missing values
    - Text analysis learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data.
    - File and Image analysis extract file sizes, creation dates and dimensions and scan for truncated images or those containing EXIF information.

- **dabl(Data Analysis Baseline Library)**: dabl has been created by Andreas Mueller and it tries to help make supervised machine learning more accessible for beginners, and reduce boiler plate for common tasks. Dabl takes inspirations from scikit-learn and auto-sklearn.

- **missingno**: Data in real life is messy and missingno helps us to deal with missing values in a dataset with the help of visualisations. With over 2k stars on github, this library is already very popular.

- **ppscore**: ppscorebrought to you by the makers of Bamboolib, is a Python implementation of the Predictive Power Score (PPS). The PPS is an asymmetric, data-type-agnostic score that can detect linear or non-linear relationships between two columns. The score ranges from 0 (no predictive power) to 1 (perfect predictive power). It can be used as an alternative to the correlation (matrix).
- **Bamboolib**: bamboolib is a GUI for data exploration & transformation in Python Pandas. It is compatible with Jupyter Notebook and JupyterLab. Bamboolib is an otherwise closed source library but can be used for free for open data via Binder or Kaggle.

### Visualization
- **Seaborn**
- **Plotly**
- **Bokeh**
- **AutoViz**: AutoViz automatically visualizes any dataset, any size with a single line of code.It performs automatic visualization of any dataset with one line. Give any input file (CSV, txt or json) and AutoViz will visualize it.
- **Cufflinks**: Cufflinks library binds the power of plotly with the flexibility of pandas for easy plotting. Let’s now see how we can install the library and get it working in pandas.


### ML/DL Libraries
- **Scikit-learn**
- **TensorFlow**
- **Keras**
- **pytorch**
- **fastai**

### NLP
- **spacy**
- **Gensim**
- **NLTK**
- **coreNLP**
- **Flashtext**: Flastext lets you extract Keywords from sentence or Replace keywords in sentences.It is based on the FlashText algorithm and is considerably faster than Regular Expressions for NLP tasks.

- **Numerizer**: Numerizer is a Python module for converting natural language numbers into ints and floats. It is a port of the Ruby gem numerizer. This could be really useful when preprocessing text data.

- **Emot**: Emot is an Emoji and Emoticons detection package for Python. It can come in real handy when we have to preprocess our text data to get rid of the emoticons.

### Computer Vision
- **OpenCV**
- **scikit-image**

### Hosting
- **Flask**
- **Streamlit**
- **Gradio**: Gradio lets you build and deploy web apps for your machine learning models in as little as three lines of code. It serves the same purpose as Streamlit or Flask, but I found it much faster and easier to get a model deployed.
    - It allows for further model validation. Specifically, it allows you to interactively test different inputs into the model.
    - It's a good way to conduct demos.
    - It's easy to implement and distribute because the web app is accessible by anyone through a public link.


### Web Scrapping
- **Scrapy**: Scrapy is also pronounced as the spider bots. This library is responsible for crawling programs and retrieving of the structured data from the web applications.  This open source library is written in Python. As per the name it was designed for scraping. It is the complete framework with the potential to collect data through APIs and act like a crawler. Through it, one can write codes, reuse universal programs and create scalable crawlers for their application. Scrapy is created across the Spider class which contains the instructions for a crawler.
- **BeautifulSoup**: BeautifulSoup enables web scraping from HTML and XML documents. BeautifulSoup automatically detects encodings and gracefully handles HTML documents even with special characters. We can navigate a parsed document and find what we need which makes it quick and painless to extract the data from the webpages. In this article, we will learn how to build web scrapers using Beautiful Soup in detail.

### Other Libraries
- **PyQt**: PyQt is a Python binding toolkit for cross-platform GUI. It is implemented as a Python plugin. PyQt is a free application which is licensed under the GNU General Public License. PyQt have almost 440 classes and more than 6000 functions to make a user’s journey easier. It includes classes for accessing SQL databases, an XML parser, active X controller classes, SVG support, and many more useful resources to reduce user’s challenges.

